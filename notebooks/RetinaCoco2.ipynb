{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "from fastai.conv_learner import *\n",
    "from matplotlib import patches, patheffects\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "coco_path = Path('/scratch/arka/Ark_git_files/coco/')\n",
    "ann_path = coco_path / 'annotations'\n",
    "train_path = coco_path / 'train2017'\n",
    "val_path = coco_path / 'val2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances_train2017 = json.load((ann_path / 'instances_train2017.json').open('r'))\n",
    "instances_val2017 = json.load((ann_path / 'instances_val2017.json').open('r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']\n",
    "\n",
    "FILE_NAME,ID,IMG_ID,CAT_ID,BBOX = 'file_name','id','image_id','category_id','bbox'\n",
    "\n",
    "JPEGS = 'imgs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = json.load(open('category.json', 'r'))\n",
    "trn_fns = json.load(open('trn_fns.json', 'r'))\n",
    "trn_ids = json.load(open('trn_ids.json', 'r'))\n",
    "trn_ids = [str(o) for o in trn_ids]\n",
    "trn_anno = json.load(open('trn_anno.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1],a[2]-a[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop. See below when to continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_fns_corr = dict()\n",
    "for k, v in tqdm(trn_fns.items()):\n",
    "    if k in trn_ids:\n",
    "        trn_fns_corr[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = dict((o[ID], o['name']) for o in instances_train2017[CATEGORIES])\n",
    "trn_fns = dict((o[ID], o[FILE_NAME]) for o in instances_train2017[IMAGES])\n",
    "trn_ids = [o[ID] for o in instances_train2017[IMAGES]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in cats.items():\n",
    "    if (' ' in value):       \n",
    "        cats[key]=value.replace(' ','_')\n",
    "#         print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_anno = collections.defaultdict(list)\n",
    "for o in instances_train2017[ANNOTATIONS]:\n",
    "    bb1 = o[BBOX]\n",
    "    assert len(bb1) == 4\n",
    "    bb = bb1\n",
    "#     print(bb)\n",
    "    bb = np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
    "    \n",
    "    trn_anno[o[IMG_ID]].append((bb.tolist(),o[CAT_ID]))\n",
    "        \n",
    "len(trn_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict = defaultdict(list)\n",
    "for o in trn_ids:\n",
    "    ann = trn_anno[o]\n",
    "    for a in ann:\n",
    "        cdict[o].append(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdict[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids],\n",
    "    'cat': [' '.join([cats[str(p)] for p in cdict[o]]) for o in trn_ids]}, columns=['fn','cat'])\n",
    "csvs = coco_path / 'csv_new' / 'train_cls.csv'\n",
    "csvs.parent.mkdir(exist_ok=True, parents=True)\n",
    "dfm.to_csv(csvs, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(a[0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdict = defaultdict(list)\n",
    "for o in trn_ids:\n",
    "    ann = trn_anno[o]\n",
    "    for a in ann:\n",
    "        bdict[o].append(str(np.round(a[0]).astype(int).tolist()).strip('[').strip(']').replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdict[o][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(bdict[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(cats, open('category.json', 'w'))\n",
    "json.dump(trn_fns_corr, open('trn_fns.json', 'w'))\n",
    "json.dump(trn_ids_corr, open('trn_ids.json', 'w'))\n",
    "# json.dump(trn_anno, open('trn_anno.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], \n",
    "                   'bbox': [' '.join(bdict[o]) for o in trn_ids]}, columns=['fn','bbox'])\n",
    "csvs = coco_path / 'csv_new' / 'train_bbx.csv'\n",
    "csvs.parent.mkdir(exist_ok=True, parents=True)\n",
    "df.to_csv(csvs, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bbox'][1].split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'md' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9df4ac052dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m984\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrn_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m984\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'md' is not defined"
     ]
    }
   ],
   "source": [
    "x = md.trn_ds.get_x(984)\n",
    "y = md.trn_ds.get_y(984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md.trn_ds.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "md.trn_ds.transform.tfms[3](x3, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, y1 = md.trn_ds.transform.tfms[0](x, y)\n",
    "x2, y2 = md.trn_ds.transform.tfms[1](x1, y1)\n",
    "x3, y3 = md.trn_ds.transform.tfms[2](x2, y2)\n",
    "x4, y4 = md.trn_ds.transform.tfms[3](x3, y3)\n",
    "x5, y5 = md.trn_ds.transform.tfms[4](x4, y4)\n",
    "x6, y6 = md.trn_ds.transform.tfms[4](x5, y5)\n",
    "\n",
    "print(x6, y6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 1116/93813 [00:34<47:45, 32.35it/s] "
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for x, y in tqdm(md.trn_ds):\n",
    "    if len(y.nonzero()[0]) == 0:\n",
    "        print(c)\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MBB_CSV = coco_path / 'csv_new' / 'train_bbx.csv'\n",
    "JPEGS = 'imgs'\n",
    "sz=224\n",
    "bs=32\n",
    "f_model = resnet34\n",
    "aug_tfms = [RandomRotate(3, p=0.5, tfm_y=TfmType.COORD),\n",
    "            RandomLighting(0.05, 0.05, tfm_y=TfmType.COORD),\n",
    "            RandomFlip(tfm_y=TfmType.COORD)]\n",
    "tfms = tfms_from_model(f_model, sz, aug_tfms=aug_tfms, crop_type=CropType.NO, tfm_y=TfmType.COORD)\n",
    "md = ImageClassifierData.from_csv(coco_path, JPEGS, MBB_CSV, tfms=tfms, bs=bs, continuous=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as mcolors\n",
    "from cycler import cycler\n",
    "\n",
    "def get_cmap(N):\n",
    "    color_norm  = mcolors.Normalize(vmin=0, vmax=N-1)\n",
    "    return cmx.ScalarMappable(norm=color_norm, cmap='Set3').to_rgba\n",
    "\n",
    "num_colr = 12\n",
    "cmap = get_cmap(num_colr)\n",
    "colr_list = [cmap(float(x)) for x in range(num_colr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ground_truth(ax, im, bbox, clas=None, prs=None, thresh=0.3):\n",
    "    bb = [bb_hw(o) for o in bbox.reshape(-1,4)]\n",
    "    if prs is None:  prs  = [None]*len(bb)\n",
    "    if clas is None: clas = [None]*len(bb)\n",
    "    ax = show_img(im, ax=ax)\n",
    "    for i,(b,c,pr) in enumerate(zip(bb, clas, prs)):\n",
    "        if((b[2]>0) and (pr is None or pr > thresh)):\n",
    "            draw_rect(ax, b, color=colr_list[i%num_colr])\n",
    "            txt = f'{i}: '\n",
    "            if c is not None: txt += ('bg' if c==len(id2cat) else id2cat[c])\n",
    "            if pr is not None: txt += f' {pr:.2f}'\n",
    "            draw_text(ax, b[:2], txt, color=colr_list[i%num_colr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatLblDataset(Dataset):\n",
    "    def __init__(self, ds, y2):\n",
    "        self.ds,self.y2 = ds,y2\n",
    "        self.sz = ds.sz\n",
    "    def __len__(self): return len(self.ds)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x,y = self.ds[i]\n",
    "        return (x, (y,self.y2[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = [[cats[str(p[1])] for p in trn_anno[o]] for o in trn_ids]\n",
    "# mc = [[cats[p[1]] for p in trn_anno[o]] for o in trn_ids]\n",
    "\n",
    "# mc = []\n",
    "# trn_ids_corr = []\n",
    "# for o in trn_ids:\n",
    "#     if o in trn_anno:\n",
    "#         tmpl = [cats[str(p[1])] for p in trn_anno[o]]\n",
    "#         mc.append(tmpl)\n",
    "#         trn_ids_corr.append(o)\n",
    "#     else:\n",
    "#         print(o)\n",
    "id2cat = list(cats.values())\n",
    "cat2id = {v:k for k,v in enumerate(id2cat)}\n",
    "mcs = np.array([np.array([cat2id[p] for p in o]) for o in mc]); mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idxs = get_cv_idxs(len(trn_ids))\n",
    "((val_mcs,trn_mcs),) = split_by_idx(val_idxs, mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(trn_ids) == len(trn_fns)\n",
    "assert len(trn_ids) == len(trn_anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(md.trn_ds), len(trn_mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds2 = ConcatLblDataset(md.trn_ds, trn_mcs)\n",
    "val_ds2 = ConcatLblDataset(md.val_ds, val_mcs)\n",
    "md.trn_dl.dataset = trn_ds2\n",
    "md.fix_dl.dataset = trn_ds2\n",
    "md.val_dl.dataset = val_ds2\n",
    "md.aug_dl.dataset = val_ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=to_np(next(iter(md.trn_dl)))\n",
    "x=md.trn_ds.ds.denorm(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.set_xticks(np.linspace(0, 224, 8))\n",
    "    ax.set_yticks(np.linspace(0, 224, 8))\n",
    "    ax.grid()\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    return ax\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b, color='white'):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n",
    "    draw_outline(patch, 4)\n",
    "\n",
    "def draw_text(ax, xy, txt, sz=14, color='white'):\n",
    "    text = ax.text(*xy, txt,\n",
    "        verticalalignment='top', color=color, fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    show_ground_truth(ax, x[i], y[0][i], y[1][i])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw2corners(ctr, hw): return torch.cat([ctr-hw/2, ctr+hw/2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "anc_grids = [28,14,7,4,2] #Depends of the initial size 224.\n",
    "# anc_zooms = [1., 2**(1/3), 2**(2/3)]\n",
    "anc_zooms = [1]\n",
    "# anc_ratios = [(1.,1.), (1.,2), (2,1.)]\n",
    "anc_ratios = [(1.,1.)]\n",
    "anchor_scales = [(anz*i,anz*j) for anz in anc_zooms for (i,j) in anc_ratios]\n",
    "anc_offsets = [1/(o*2) for o in anc_grids]\n",
    "anc_x = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_y = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n",
    "                        for ao,ag in zip(anc_offsets,anc_grids)])\n",
    "anc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)\n",
    "anc_sizes  =   np.concatenate([np.array([[o/ag,p/ag] for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids])\n",
    "grid_sizes = V(np.concatenate([np.array([ 1/ag       for i in range(ag*ag) for o,p in anchor_scales])\n",
    "               for ag in anc_grids]), requires_grad=False).unsqueeze(1)\n",
    "anchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), requires_grad=False).float()\n",
    "anchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(anc_x, anc_y)\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clas = len(id2cat)+1\n",
    "n_act = k*(4+n_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50 = resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_out(k):\n",
    "    return (k-1)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FPN_backbone(nn.Module):\n",
    "    def __init__(self, inch_list):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.backbone = backbone\n",
    "        \n",
    "        # expects c3, c4, c5 channel dims\n",
    "        self.inch_list = inch_list\n",
    "        self.feat_size = 256\n",
    "        self.p7_gen = nn.Conv2d(in_channels=self.feat_size, out_channels=self.feat_size, stride=2, kernel_size=3,\n",
    "                               padding=1)\n",
    "        self.p6_gen = nn.Conv2d(in_channels=self.inch_list[2], \n",
    "                            out_channels=self.feat_size, kernel_size=3, stride=2, padding=pad_out(3))\n",
    "        self.p5_gen1 = nn.Conv2d(in_channels=self.inch_list[2], \n",
    "                                 out_channels=self.feat_size, kernel_size=1, padding=pad_out(1))\n",
    "#         self.p5_gen2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.p5_gen3 = nn.Conv2d(in_channels=self.feat_size, out_channels=self.feat_size,\n",
    "                                kernel_size=3, padding=pad_out(3))\n",
    "        \n",
    "        self.p4_gen1 = nn.Conv2d(in_channels=self.inch_list[1], out_channels=self.feat_size, kernel_size=1,\n",
    "                                padding=pad_out(1))\n",
    "#         self.p4_gen2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.p4_gen3 = nn.Conv2d(in_channels=self.feat_size, out_channels=self.feat_size, kernel_size=3, \n",
    "                                padding=pad_out(3))\n",
    "        \n",
    "        self.p3_gen1 = nn.Conv2d(in_channels=self.inch_list[0], out_channels=self.feat_size, kernel_size=1,\n",
    "                                padding=pad_out(1))\n",
    "        self.p3_gen2 = nn.Conv2d(in_channels=self.feat_size, out_channels=self.feat_size, kernel_size=3,\n",
    "                                padding=pad_out(3))\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        # expects inp to be output of c3, c4, c5\n",
    "        c3 = inp[0]\n",
    "        c4 = inp[1]\n",
    "        c5 = inp[2]\n",
    "        p51 = self.p5_gen1(c5)\n",
    "        p5_out = self.p5_gen3(p51)\n",
    "        \n",
    "#         p5_up = self.p5_gen2(p51)\n",
    "        p5_up = F.interpolate(p51, scale_factor=2)\n",
    "        p41 = self.p4_gen1(c4) + p5_up\n",
    "        p4_out = self.p4_gen3(p41)\n",
    "        \n",
    "#         p4_up = self.p4_gen2(p41)\n",
    "        p4_up = F.interpolate(p41, scale_factor=2)\n",
    "        p31 = self.p3_gen1(c3) + p4_up\n",
    "        p3_out = self.p3_gen2(p31)\n",
    "        \n",
    "        p6_out = self.p6_gen(c5)\n",
    "        \n",
    "        p7_out = self.p7_gen(F.relu(p6_out))\n",
    "        \n",
    "        return [p3_out, p4_out, p5_out, p6_out, p7_out]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_conv(x,k):\n",
    "    bs,nf,gx,gy = x.size()\n",
    "    x = x.permute(0,2,3,1).contiguous()\n",
    "    return x.view(bs,-1,nf//k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vals(mdl):\n",
    "    for m in mdl.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "            m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data.fill_(1)\n",
    "            m.bias.data.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classf_model(nn.Module):\n",
    "    def __init__(self, fs=256, na=9, nc=80):\n",
    "        super().__init__()\n",
    "        self.na = na\n",
    "        self.nc = nc\n",
    "        self.feat_size = fs\n",
    "        self.cls_modl = nn.Sequential(*nn.ModuleList([nn.Conv2d(in_channels=self.feat_size,\n",
    "                                                                           out_channels=self.feat_size,\n",
    "                                                                           kernel_size=3, padding=1)]*4),\n",
    "                                                  nn.Conv2d(in_channels=self.feat_size,\n",
    "                                                            out_channels=self.na * self.nc,\n",
    "                                                            kernel_size=3, padding=1))\n",
    "        initialize_vals(self.cls_modl)\n",
    "    def forward(self, inp):\n",
    "#         import pdb; pdb.set_trace();\n",
    "        out = self.cls_modl(inp)\n",
    "        out2 = flatten_conv(out, self.na)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class regress_model(nn.Module):\n",
    "    def __init__(self, fs=256, na=9, nc=80):\n",
    "        super().__init__()\n",
    "        self.na = na\n",
    "        self.nc = nc\n",
    "        self.feat_size = fs\n",
    "        self.reg_model = nn.Sequential(*nn.ModuleList([nn.Conv2d(in_channels=self.feat_size,\n",
    "                                                                           out_channels=self.feat_size,\n",
    "                                                                           kernel_size=3, padding=1)]*4),\n",
    "                                                  nn.Conv2d(in_channels=self.feat_size,\n",
    "                                                            out_channels=self.na * 4,\n",
    "                                                            kernel_size=3, padding=1))\n",
    "        initialize_vals(self.reg_model)\n",
    "    def forward(self, inp):\n",
    "        out = self.reg_model(inp)\n",
    "        out2 = flatten_conv(out, self.na)\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class retina_net_model(nn.Module):\n",
    "    def __init__(self, resnet_model, na=9, nc=81):\n",
    "        super().__init__()\n",
    "        self.res_backbone = resnet_model\n",
    "        self.fpn_sizes = [self.res_backbone.layer2[-1].conv3.out_channels, \n",
    "                          self.res_backbone.layer3[-1].conv3.out_channels,\n",
    "                          self.res_backbone.layer4[-1].conv3.out_channels]\n",
    "        self.feat_size = 256\n",
    "        self.num_anch = na\n",
    "        self.num_class = nc\n",
    "        self.fpn = FPN_backbone(self.fpn_sizes)\n",
    "        self.cls_model = classf_model(self.feat_size, self.num_anch, self.num_class)\n",
    "        self.reg_model = regress_model(self.feat_size, self.num_anch, self.num_class)\n",
    "        \n",
    "        \n",
    "    def forward(self, inp):\n",
    "        x = self.res_backbone.conv1(inp)\n",
    "        x = self.res_backbone.bn1(x)\n",
    "        x = self.res_backbone.relu(x)\n",
    "        x = self.res_backbone.maxpool(x)\n",
    "        x1 = self.res_backbone.layer1(x)\n",
    "        x2 = self.res_backbone.layer2(x1)\n",
    "        x3 = self.res_backbone.layer3(x2)\n",
    "        x4 = self.res_backbone.layer4(x3)\n",
    "\n",
    "        features = self.fpn([x2, x3, x4])\n",
    "#         features = self.fpn([x4])\n",
    "        out_cls = []\n",
    "        out_bbx = []\n",
    "        for p in features:\n",
    "            out_cls.append(self.cls_model(p))\n",
    "            out_bbx.append(self.reg_model(p))\n",
    "        \n",
    "        return [torch.cat(out_cls, dim=1),\n",
    "                torch.cat(out_bbx, dim=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_embedding(labels, num_classes):\n",
    "    return torch.eye(num_classes)[labels.data.cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCE_Loss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, pred, targ):\n",
    "        t = one_hot_embedding(targ, self.num_classes+1)\n",
    "        t = V(t[:,:-1].contiguous())#.cpu()\n",
    "        x = pred[:,:-1]\n",
    "        w = self.get_weight(x,t)\n",
    "        return F.binary_cross_entropy_with_logits(x, t, w, reduction='element_wise_mean')/self.num_classes\n",
    "    \n",
    "    def get_weight(self,x,t): return None\n",
    "\n",
    "    \n",
    "def intersect(box_a, box_b):\n",
    "    max_xy = torch.min(box_a[:, None, 2:], box_b[None, :, 2:])\n",
    "    min_xy = torch.max(box_a[:, None, :2], box_b[None, :, :2])\n",
    "    inter = torch.clamp((max_xy - min_xy), min=0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]\n",
    "\n",
    "def box_sz(b): return ((b[:, 2]-b[:, 0]) * (b[:, 3]-b[:, 1]))\n",
    "\n",
    "def jaccard(box_a, box_b):\n",
    "    inter = intersect(box_a, box_b)\n",
    "    union = box_sz(box_a).unsqueeze(1) + box_sz(box_b).unsqueeze(0) - inter\n",
    "    return inter / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y(bbox,clas):\n",
    "    bbox = bbox.view(-1,4)/sz\n",
    "    bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n",
    "    return bbox[bb_keep],clas[bb_keep]\n",
    "\n",
    "\n",
    "def actn_to_bb(actn, anchors):\n",
    "#     import pdb; pdb.set_trace()\n",
    "\n",
    "    actn_bbs = torch.tanh(actn)\n",
    "    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]\n",
    "    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n",
    "    return hw2corners(actn_centers, actn_hw)\n",
    "\n",
    "def map_to_ground_truth(overlaps, print_it=False):\n",
    "    prior_overlap, prior_idx = overlaps.max(1)\n",
    "    if print_it: print(prior_overlap)\n",
    "#     pdb.set_trace()\n",
    "    gt_overlap, gt_idx = overlaps.max(0)\n",
    "    gt_overlap[prior_idx] = 1.99\n",
    "    for i,o in enumerate(prior_idx): gt_idx[o] = i\n",
    "    return gt_overlap,gt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = BCE_Loss(len(id2cat))\n",
    "# loss_f = nn.CrossEntropyLoss()\n",
    "\n",
    "def ssd_1_loss(b_c,b_bb,bbox,clas,print_it=False):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    bbox,clas = get_y(bbox,clas)\n",
    "    a_ic = actn_to_bb(b_bb, anchors)\n",
    "    overlaps = jaccard(bbox.data, anchor_cnr.data)\n",
    "    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)\n",
    "    gt_clas = clas[gt_idx]\n",
    "    pos = gt_overlap > 0.4\n",
    "    pos_idx = torch.nonzero(pos)[:,0]\n",
    "    gt_clas[1-pos] = len(id2cat)\n",
    "    gt_bbox = bbox[gt_idx]\n",
    "    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n",
    "    clas_loss  = loss_f(b_c, gt_clas)\n",
    "    return loc_loss, clas_loss\n",
    "\n",
    "def ssd_loss(pred,targ,print_it=False):\n",
    "    lcs,lls = 0.,0.\n",
    "    for b_c,b_bb,bbox,clas in zip(*pred,*targ):\n",
    "        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it)\n",
    "        lls += loc_loss\n",
    "        lcs += clas_loss\n",
    "#     if print_it: \n",
    "#     print(f'loc: {lls.data[0]}, clas: {lcs.data[0]}')\n",
    "    return lls+lcs/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_model = retina_net_model(res50, 1, n_clas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner.from_model_data(retina_model, md)\n",
    "learn.crit = ssd_loss\n",
    "learn.opt_fn = optim.Adam\n",
    "learn.fit(1e-3, 1, cycle_len=10, best_save_name='retina_first_try')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x, y in tqdm(md.fix_dl):\n",
    "    for i in range(len(y[0])):\n",
    "        bbox = y[0][i]\n",
    "        clas = y[1][i]\n",
    "        bbox,clas = get_y(bbox,clas)\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x, y in tqdm(trn_ds2):\n",
    "    bbox, clas = get_y(T(y[0]), T(y[1]))\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = trn_ds2.ds[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y.nonzero()[0]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds2.ds.fnames[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds2.ds.get_y(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(MBB_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[c]['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.iloc[46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(MBB_CSV)\n",
    "\n",
    "for i in range(len(df1)):\n",
    "    tmp = df1['bbox'][i].split(' ')\n",
    "    if len(tmp) % 4 != 0:\n",
    "        print(i)\n",
    "    t1 = [int(t) for t in tmp]\n",
    "#     print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['bbox'][46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(t) for t in tmp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(md.fix_dl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
